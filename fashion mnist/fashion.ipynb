{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv('fashion-mnist_train.csv')\n",
    "test = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#TRAIN SET\n",
    "X_train = train.drop('label', axis = 1)\n",
    "y_train = train['label']\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "X_train = X_train / X_train.max() #Normalization\n",
    "\n",
    "#TEST SET\n",
    "X_test = test.drop('label', axis = 1)\n",
    "y_test = test['label']\n",
    "X_test = X_test.values.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test / X_test.max()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.05, random_state =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.4755 - loss: 1.3480 - val_accuracy: 0.7913 - val_loss: 0.5197\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.8125 - loss: 0.5036 - val_accuracy: 0.8650 - val_loss: 0.3781\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.8702 - loss: 0.3712 - val_accuracy: 0.8797 - val_loss: 0.3295\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.8877 - loss: 0.3188 - val_accuracy: 0.8980 - val_loss: 0.2822\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.8983 - loss: 0.2853 - val_accuracy: 0.9117 - val_loss: 0.2543\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9135 - loss: 0.2471 - val_accuracy: 0.9067 - val_loss: 0.2644\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9197 - loss: 0.2244 - val_accuracy: 0.9223 - val_loss: 0.2270\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9276 - loss: 0.2015 - val_accuracy: 0.9210 - val_loss: 0.2387\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9331 - loss: 0.1886 - val_accuracy: 0.9227 - val_loss: 0.2305\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9385 - loss: 0.1726 - val_accuracy: 0.9227 - val_loss: 0.2139\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9490 - loss: 0.1437 - val_accuracy: 0.9287 - val_loss: 0.2219\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9528 - loss: 0.1328 - val_accuracy: 0.9190 - val_loss: 0.2308\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9580 - loss: 0.1166 - val_accuracy: 0.9153 - val_loss: 0.2456\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9568 - loss: 0.1195 - val_accuracy: 0.9233 - val_loss: 0.2386\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9679 - loss: 0.0905 - val_accuracy: 0.9210 - val_loss: 0.2618\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9681 - loss: 0.0905 - val_accuracy: 0.9173 - val_loss: 0.2884\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9718 - loss: 0.0804 - val_accuracy: 0.9207 - val_loss: 0.3126\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9730 - loss: 0.0727 - val_accuracy: 0.9227 - val_loss: 0.2836\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9813 - loss: 0.0544 - val_accuracy: 0.9200 - val_loss: 0.3357\n",
      "Epoch 20/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9788 - loss: 0.0585 - val_accuracy: 0.9250 - val_loss: 0.3133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x140e08d30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tfl.Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', \n",
    "                     input_shape = (28, 28, 1), activation = 'relu'))\n",
    "model.add(tfl.MaxPooling2D((2,2)))\n",
    "model.add(tfl.Conv2D(128, kernel_size = (3,3), padding = 'same', \n",
    "                     activation = 'relu'))\n",
    "model.add(tfl.MaxPooling2D((2,2)))\n",
    "model.add(tfl.Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', \n",
    "                     activation = 'relu'))\n",
    "model.add(tfl.MaxPooling2D(2,2))\n",
    "model.add(tfl.Conv2D(filters = 512, kernel_size = (3,3), padding = 'same', \n",
    "                     activation = 'relu'))\n",
    "model.add(tfl.MaxPooling2D(2,2))\n",
    "model.add(tfl.Conv2D(filters = 1024, kernel_size = (3,3), padding = 'same', \n",
    "                     activation = 'relu'))\n",
    "model.add(tfl.GlobalAveragePooling2D())\n",
    "model.add(tfl.Flatten())\n",
    "model.add(tfl.Dense(256, activation = 'relu'))\n",
    "model.add(tfl.Dropout(0.5))\n",
    "model.add(tfl.Dense(128, activation = 'relu'))\n",
    "model.add(tfl.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), \n",
    "              metrics = ['accuracy'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, \n",
    "                                                  restore_best_weights = True)\n",
    "\n",
    "model.fit(x = X_train, y = y_train, batch_size = 512, epochs = 100, callbacks = [early_stopping], \n",
    "          validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "ACCURACY SCORE: 0.9266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred_probs = model.predict(X_test)\n",
    "pred_labels = tf.argmax(pred_probs, axis = 1)\n",
    "pred_labels \n",
    "print('ACCURACY SCORE:', accuracy_score(pred_labels, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
