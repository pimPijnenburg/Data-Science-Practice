{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "df = pd.read_csv('data.csv', index_col = 'ID')     #'P' = Patient    'H' = Healthy\n",
    "df['class'] = df['class'].astype('category')\n",
    "\n",
    "#Group by class and calculate the mean. Afterwards, transpose so the two classes are the only two columns\n",
    "classes = df.groupby('class', observed= True).mean()\n",
    "classes_t = classes.T\n",
    "\n",
    "# Function to extract ending digits from index\n",
    "def extract_task(df): \n",
    "    index = df.index.astype(str)\n",
    "    tasks = index.str.extract(r'(\\d{1,2})$', expand=False).astype(int)\n",
    "    return tasks\n",
    "classes_t['task'] = extract_task(classes_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> MANN-WHITNEY U TEST </h4> \n",
    "With this test, we can see if there is a significant difference between the distribution of 'H' and 'P'. <br>\n",
    "If the test is significant, we can reject H0 that there is no difference between the distributions of values between 'H' and 'P'\n",
    "\n",
    "<h4> BONFERRONI TEST </h4>\n",
    "The Bonferroni test corrects for the many pvalues that are generated between the observations. Since it is important that Type II errors get avoided, I chose for Bonferroni since this is a rather conservative test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>H_mean</th>\n",
       "      <th>P_mean</th>\n",
       "      <th>task</th>\n",
       "      <th>difference_pval</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>significant_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_of_pendown25</th>\n",
       "      <td>82.023529</td>\n",
       "      <td>89.483146</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_time25</th>\n",
       "      <td>36448.823529</td>\n",
       "      <td>49471.235955</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.728839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_mean25</th>\n",
       "      <td>1721.033135</td>\n",
       "      <td>1542.248773</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_var25</th>\n",
       "      <td>160722.644250</td>\n",
       "      <td>165295.761342</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time25</th>\n",
       "      <td>107617.294118</td>\n",
       "      <td>218246.168539</td>\n",
       "      <td>25</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>0.225793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class                    H_mean         P_mean  task  difference_pval  \\\n",
       "num_of_pendown25      82.023529      89.483146    25         1.000000   \n",
       "paper_time25       36448.823529   49471.235955    25         0.000059   \n",
       "pressure_mean25     1721.033135    1542.248773    25         1.000000   \n",
       "pressure_var25    160722.644250  165295.761342    25         1.000000   \n",
       "total_time25      107617.294118  218246.168539    25         0.016017   \n",
       "\n",
       "class             effect_size  significant_difference  \n",
       "num_of_pendown25     0.273650                       0  \n",
       "paper_time25         0.728839                       1  \n",
       "pressure_mean25      0.576080                       0  \n",
       "pressure_var25       0.080493                       0  \n",
       "total_time25         0.225793                       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_p = df[df['class'] == 'P'] #Dataframe with people diagnosed with alzheimers\n",
    "df_h = df[df['class'] == 'H'] #Dataframe with healthy people\n",
    "\n",
    "p_values = list()\n",
    "effect_sizes = list()\n",
    "\n",
    "def cohens_d(x, y): #Calculating the effect size\n",
    "    return (np.abs(np.mean(x) - np.mean(y))) / np.sqrt((np.std(x, ddof=1) ** 2 + np.std(y, ddof=1) ** 2) / 2)\n",
    "\n",
    "\n",
    "for feature in df.columns[:-1]:\n",
    "    data_p = df_p[feature]\n",
    "    data_h = df_h[feature]\n",
    "    \n",
    "    value, p_val = stats.mannwhitneyu(data_p, data_h)\n",
    "    p_values.append(p_val)\n",
    "    \n",
    "    d = cohens_d(df_p[feature], df_h[feature])\n",
    "    effect_sizes.append(d)  \n",
    "\n",
    "_, corrected_pvals, _, _ = multipletests(p_values, alpha = 0.05, method = 'bonferroni')\n",
    "\n",
    "classes_t['difference_pval'] = corrected_pvals\n",
    "classes_t['effect_size'] = effect_sizes\n",
    "classes_t['significant_difference'] = (classes_t['difference_pval'] <= 0.05).astype(int)\n",
    "\n",
    "classes_t = classes_t.rename(columns= {'H': 'H_mean', 'P': 'P_mean'})\n",
    "\n",
    "display(classes_t.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>H_mean</th>\n",
       "      <th>P_mean</th>\n",
       "      <th>task</th>\n",
       "      <th>difference_pval</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>significant_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_time23</th>\n",
       "      <td>11816.870588</td>\n",
       "      <td>17025.561798</td>\n",
       "      <td>23</td>\n",
       "      <td>6.062692e-14</td>\n",
       "      <td>0.220935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time15</th>\n",
       "      <td>14841.682353</td>\n",
       "      <td>53423.022472</td>\n",
       "      <td>15</td>\n",
       "      <td>2.127553e-12</td>\n",
       "      <td>0.878697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_time23</th>\n",
       "      <td>7383.752941</td>\n",
       "      <td>9785.393258</td>\n",
       "      <td>23</td>\n",
       "      <td>2.147543e-12</td>\n",
       "      <td>0.105286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_time15</th>\n",
       "      <td>9390.211765</td>\n",
       "      <td>43798.303371</td>\n",
       "      <td>15</td>\n",
       "      <td>2.944023e-11</td>\n",
       "      <td>0.833366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time17</th>\n",
       "      <td>34972.223529</td>\n",
       "      <td>74392.303371</td>\n",
       "      <td>17</td>\n",
       "      <td>6.999588e-11</td>\n",
       "      <td>0.496649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class               H_mean        P_mean  task  difference_pval  effect_size  \\\n",
       "total_time23  11816.870588  17025.561798    23     6.062692e-14     0.220935   \n",
       "total_time15  14841.682353  53423.022472    15     2.127553e-12     0.878697   \n",
       "air_time23     7383.752941   9785.393258    23     2.147543e-12     0.105286   \n",
       "air_time15     9390.211765  43798.303371    15     2.944023e-11     0.833366   \n",
       "total_time17  34972.223529  74392.303371    17     6.999588e-11     0.496649   \n",
       "\n",
       "class         significant_difference  \n",
       "total_time23                       1  \n",
       "total_time15                       1  \n",
       "air_time23                         1  \n",
       "air_time15                         1  \n",
       "total_time17                       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time23</th>\n",
       "      <th>total_time15</th>\n",
       "      <th>air_time23</th>\n",
       "      <th>air_time15</th>\n",
       "      <th>total_time17</th>\n",
       "      <th>paper_time23</th>\n",
       "      <th>air_time17</th>\n",
       "      <th>paper_time17</th>\n",
       "      <th>total_time6</th>\n",
       "      <th>air_time16</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_jerk_on_paper3</th>\n",
       "      <th>mean_acc_on_paper2</th>\n",
       "      <th>pressure_var21</th>\n",
       "      <th>mean_jerk_in_air25</th>\n",
       "      <th>mean_gmrt1</th>\n",
       "      <th>num_of_pendown7</th>\n",
       "      <th>mean_gmrt9</th>\n",
       "      <th>gmrt_on_paper22</th>\n",
       "      <th>gmrt_on_paper15</th>\n",
       "      <th>gmrt_on_paper23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_1</th>\n",
       "      <td>16160</td>\n",
       "      <td>32384</td>\n",
       "      <td>10965</td>\n",
       "      <td>17354</td>\n",
       "      <td>43285</td>\n",
       "      <td>5195</td>\n",
       "      <td>26660</td>\n",
       "      <td>16625</td>\n",
       "      <td>7675</td>\n",
       "      <td>3730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>0.076406</td>\n",
       "      <td>91381.55699</td>\n",
       "      <td>0.141434</td>\n",
       "      <td>103.828754</td>\n",
       "      <td>4</td>\n",
       "      <td>690.253070</td>\n",
       "      <td>175.179965</td>\n",
       "      <td>57.804271</td>\n",
       "      <td>190.158460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_2</th>\n",
       "      <td>29900</td>\n",
       "      <td>41200</td>\n",
       "      <td>14660</td>\n",
       "      <td>26535</td>\n",
       "      <td>103935</td>\n",
       "      <td>15240</td>\n",
       "      <td>54370</td>\n",
       "      <td>49565</td>\n",
       "      <td>30080</td>\n",
       "      <td>10650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.103937</td>\n",
       "      <td>149469.69830</td>\n",
       "      <td>0.049663</td>\n",
       "      <td>99.383459</td>\n",
       "      <td>6</td>\n",
       "      <td>56.617400</td>\n",
       "      <td>56.986142</td>\n",
       "      <td>49.014189</td>\n",
       "      <td>52.977313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_3</th>\n",
       "      <td>13865</td>\n",
       "      <td>33695</td>\n",
       "      <td>7330</td>\n",
       "      <td>22345</td>\n",
       "      <td>50990</td>\n",
       "      <td>6535</td>\n",
       "      <td>27640</td>\n",
       "      <td>23350</td>\n",
       "      <td>5345</td>\n",
       "      <td>3265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.075103</td>\n",
       "      <td>54854.49989</td>\n",
       "      <td>0.178194</td>\n",
       "      <td>201.347928</td>\n",
       "      <td>5</td>\n",
       "      <td>198.257793</td>\n",
       "      <td>151.306239</td>\n",
       "      <td>85.956735</td>\n",
       "      <td>189.682156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_4</th>\n",
       "      <td>13585</td>\n",
       "      <td>28465</td>\n",
       "      <td>7205</td>\n",
       "      <td>21890</td>\n",
       "      <td>49645</td>\n",
       "      <td>6380</td>\n",
       "      <td>27000</td>\n",
       "      <td>22645</td>\n",
       "      <td>29970</td>\n",
       "      <td>9850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.129888</td>\n",
       "      <td>105063.56350</td>\n",
       "      <td>0.113905</td>\n",
       "      <td>276.298223</td>\n",
       "      <td>7</td>\n",
       "      <td>158.085598</td>\n",
       "      <td>116.624172</td>\n",
       "      <td>120.452831</td>\n",
       "      <td>166.255725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_5</th>\n",
       "      <td>10145</td>\n",
       "      <td>24360</td>\n",
       "      <td>5340</td>\n",
       "      <td>18575</td>\n",
       "      <td>37675</td>\n",
       "      <td>4805</td>\n",
       "      <td>22375</td>\n",
       "      <td>15300</td>\n",
       "      <td>11870</td>\n",
       "      <td>805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>143524.84850</td>\n",
       "      <td>0.121782</td>\n",
       "      <td>184.636510</td>\n",
       "      <td>4</td>\n",
       "      <td>151.967684</td>\n",
       "      <td>144.301940</td>\n",
       "      <td>90.797232</td>\n",
       "      <td>157.823013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_time23  total_time15  air_time23  air_time15  total_time17  \\\n",
       "ID                                                                       \n",
       "id_1         16160         32384       10965       17354         43285   \n",
       "id_2         29900         41200       14660       26535        103935   \n",
       "id_3         13865         33695        7330       22345         50990   \n",
       "id_4         13585         28465        7205       21890         49645   \n",
       "id_5         10145         24360        5340       18575         37675   \n",
       "\n",
       "      paper_time23  air_time17  paper_time17  total_time6  air_time16  ...  \\\n",
       "ID                                                                     ...   \n",
       "id_1          5195       26660         16625         7675        3730  ...   \n",
       "id_2         15240       54370         49565        30080       10650  ...   \n",
       "id_3          6535       27640         23350         5345        3265  ...   \n",
       "id_4          6380       27000         22645        29970        9850  ...   \n",
       "id_5          4805       22375         15300        11870         805  ...   \n",
       "\n",
       "      mean_jerk_on_paper3  mean_acc_on_paper2  pressure_var21  \\\n",
       "ID                                                              \n",
       "id_1             0.017351            0.076406     91381.55699   \n",
       "id_2             0.015674            0.103937    149469.69830   \n",
       "id_3             0.011406            0.075103     54854.49989   \n",
       "id_4             0.011895            0.129888    105063.56350   \n",
       "id_5             0.015170            0.081101    143524.84850   \n",
       "\n",
       "      mean_jerk_in_air25  mean_gmrt1  num_of_pendown7  mean_gmrt9  \\\n",
       "ID                                                                  \n",
       "id_1            0.141434  103.828754                4  690.253070   \n",
       "id_2            0.049663   99.383459                6   56.617400   \n",
       "id_3            0.178194  201.347928                5  198.257793   \n",
       "id_4            0.113905  276.298223                7  158.085598   \n",
       "id_5            0.121782  184.636510                4  151.967684   \n",
       "\n",
       "      gmrt_on_paper22  gmrt_on_paper15  gmrt_on_paper23  \n",
       "ID                                                       \n",
       "id_1       175.179965        57.804271       190.158460  \n",
       "id_2        56.986142        49.014189        52.977313  \n",
       "id_3       151.306239        85.956735       189.682156  \n",
       "id_4       116.624172       120.452831       166.255725  \n",
       "id_5       144.301940        90.797232       157.823013  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_features = classes_t[classes_t['significant_difference'] == 1]\n",
    "significant_features = significant_features.sort_values('difference_pval')\n",
    "display(significant_features.head())\n",
    "\n",
    "significant_features_idx = significant_features.index\n",
    "sig = df[significant_features_idx] #Dataframe with only the significant features \n",
    "\n",
    "display(sig.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> PCA </h3>\n",
    "I applied PCA to reduce the number of column sin the dataset. I wanted to capture 99% of the variance, which led to almost halve of the significant columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_1</th>\n",
       "      <td>0.145780</td>\n",
       "      <td>1.009747</td>\n",
       "      <td>-0.670994</td>\n",
       "      <td>-0.668427</td>\n",
       "      <td>-0.898119</td>\n",
       "      <td>-0.377622</td>\n",
       "      <td>0.993143</td>\n",
       "      <td>1.318765</td>\n",
       "      <td>1.025275</td>\n",
       "      <td>-0.046577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068585</td>\n",
       "      <td>-0.182752</td>\n",
       "      <td>0.165853</td>\n",
       "      <td>0.077931</td>\n",
       "      <td>-0.095847</td>\n",
       "      <td>0.049297</td>\n",
       "      <td>0.115303</td>\n",
       "      <td>-0.035538</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.105231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_2</th>\n",
       "      <td>4.458862</td>\n",
       "      <td>0.309427</td>\n",
       "      <td>-0.252775</td>\n",
       "      <td>-0.513903</td>\n",
       "      <td>-0.026872</td>\n",
       "      <td>-1.160453</td>\n",
       "      <td>-1.132002</td>\n",
       "      <td>0.917680</td>\n",
       "      <td>-0.046371</td>\n",
       "      <td>-0.397825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109880</td>\n",
       "      <td>-0.155270</td>\n",
       "      <td>-0.095353</td>\n",
       "      <td>0.086493</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.074153</td>\n",
       "      <td>0.057186</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.119461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_3</th>\n",
       "      <td>0.290307</td>\n",
       "      <td>-0.173949</td>\n",
       "      <td>-0.933445</td>\n",
       "      <td>0.345094</td>\n",
       "      <td>-0.042128</td>\n",
       "      <td>0.072288</td>\n",
       "      <td>-0.341775</td>\n",
       "      <td>-0.316597</td>\n",
       "      <td>0.097117</td>\n",
       "      <td>-0.061462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174323</td>\n",
       "      <td>0.050960</td>\n",
       "      <td>-0.135475</td>\n",
       "      <td>-0.079350</td>\n",
       "      <td>0.039035</td>\n",
       "      <td>0.064734</td>\n",
       "      <td>-0.257369</td>\n",
       "      <td>0.314196</td>\n",
       "      <td>-0.109449</td>\n",
       "      <td>0.097987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_4</th>\n",
       "      <td>2.023812</td>\n",
       "      <td>-0.596423</td>\n",
       "      <td>0.434598</td>\n",
       "      <td>0.037898</td>\n",
       "      <td>-0.197099</td>\n",
       "      <td>-0.496754</td>\n",
       "      <td>-0.376483</td>\n",
       "      <td>-0.130767</td>\n",
       "      <td>0.350506</td>\n",
       "      <td>-0.146561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347328</td>\n",
       "      <td>0.073223</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>-0.191515</td>\n",
       "      <td>-0.083507</td>\n",
       "      <td>0.131871</td>\n",
       "      <td>-0.165518</td>\n",
       "      <td>-0.006832</td>\n",
       "      <td>0.181772</td>\n",
       "      <td>-0.273191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_5</th>\n",
       "      <td>0.846310</td>\n",
       "      <td>0.354092</td>\n",
       "      <td>-1.457208</td>\n",
       "      <td>-0.234651</td>\n",
       "      <td>-0.864111</td>\n",
       "      <td>-0.801228</td>\n",
       "      <td>-0.541422</td>\n",
       "      <td>0.358469</td>\n",
       "      <td>0.791681</td>\n",
       "      <td>0.585810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037641</td>\n",
       "      <td>-0.230070</td>\n",
       "      <td>-0.130213</td>\n",
       "      <td>0.253158</td>\n",
       "      <td>0.107898</td>\n",
       "      <td>0.122623</td>\n",
       "      <td>0.067777</td>\n",
       "      <td>0.042417</td>\n",
       "      <td>0.111316</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "ID                                                                           \n",
       "id_1  0.145780  1.009747 -0.670994 -0.668427 -0.898119 -0.377622  0.993143   \n",
       "id_2  4.458862  0.309427 -0.252775 -0.513903 -0.026872 -1.160453 -1.132002   \n",
       "id_3  0.290307 -0.173949 -0.933445  0.345094 -0.042128  0.072288 -0.341775   \n",
       "id_4  2.023812 -0.596423  0.434598  0.037898 -0.197099 -0.496754 -0.376483   \n",
       "id_5  0.846310  0.354092 -1.457208 -0.234651 -0.864111 -0.801228 -0.541422   \n",
       "\n",
       "            7         8         9   ...        73        74        75  \\\n",
       "ID                                  ...                                 \n",
       "id_1  1.318765  1.025275 -0.046577  ... -0.068585 -0.182752  0.165853   \n",
       "id_2  0.917680 -0.046371 -0.397825  ... -0.109880 -0.155270 -0.095353   \n",
       "id_3 -0.316597  0.097117 -0.061462  ... -0.174323  0.050960 -0.135475   \n",
       "id_4 -0.130767  0.350506 -0.146561  ... -0.347328  0.073223  0.023111   \n",
       "id_5  0.358469  0.791681  0.585810  ...  0.037641 -0.230070 -0.130213   \n",
       "\n",
       "            76        77        78        79        80        81        82  \n",
       "ID                                                                          \n",
       "id_1  0.077931 -0.095847  0.049297  0.115303 -0.035538  0.009996  0.105231  \n",
       "id_2  0.086493  0.021690  0.074153  0.057186  0.091228  0.005370  0.119461  \n",
       "id_3 -0.079350  0.039035  0.064734 -0.257369  0.314196 -0.109449  0.097987  \n",
       "id_4 -0.191515 -0.083507  0.131871 -0.165518 -0.006832  0.181772 -0.273191  \n",
       "id_5  0.253158  0.107898  0.122623  0.067777  0.042417  0.111316  0.058655  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range= (-1, 1))\n",
    "pca = PCA(n_components= 0.99)\n",
    "sig_scaled = scaler.fit_transform(sig)\n",
    "sig_scaled_transformed = pca.fit_transform(sig_scaled)\n",
    "pca_frame = pd.DataFrame(sig_scaled_transformed, index = sig.index)\n",
    "pca_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "X_pca = pca_frame.values\n",
    "y = le.fit_transform(df['class'])\n",
    "\n",
    "X_pca_train, X_pca_test, y_train, y_test = train_test_split(X_pca, y, test_size= 0.3,random_state= 1, stratify= y, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression CV roc_auc score: 0.973970473970474\n",
      "--- LogisticRegression classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82        30\n",
      "           1       0.74      0.87      0.80        23\n",
      "\n",
      "    accuracy                           0.81        53\n",
      "   macro avg       0.81      0.82      0.81        53\n",
      "weighted avg       0.82      0.81      0.81        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#BASELINE LOGISTIC REGRESSION MODEL \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pca_logreg = LogisticRegression(random_state= 1)\n",
    "pca_logreg_scores = cross_val_score(pca_logreg, X_pca_train, y_train, cv = 5, scoring = 'roc_auc')\n",
    "print(f'{pca_logreg.__class__.__name__} CV roc_auc score: {pca_logreg_scores.mean()}')\n",
    "\n",
    "pca_logreg.fit(X_pca_train, y_train)\n",
    "pca_logreg_pred = pca_logreg.predict(X_pca_test)\n",
    "print(f'--- {pca_logreg.__class__.__name__} classification report ---')\n",
    "print(classification_report(pca_logreg_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier CV roc_auc score: 0.9600330225330225\n",
      " --- RandomForestClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83        27\n",
      "           1       0.81      0.85      0.83        26\n",
      "\n",
      "    accuracy                           0.83        53\n",
      "   macro avg       0.83      0.83      0.83        53\n",
      "weighted avg       0.83      0.83      0.83        53\n",
      "\n",
      "\n",
      "\n",
      "GradientBoostingClassifier CV roc_auc score: 0.923076923076923\n",
      " --- GradientBoostingClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.81        31\n",
      "           1       0.70      0.86      0.78        22\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.79      0.80      0.79        53\n",
      "weighted avg       0.81      0.79      0.79        53\n",
      "\n",
      "\n",
      "\n",
      "SVC CV roc_auc score: 0.966977466977467\n",
      " --- SVC classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.81        31\n",
      "           1       0.70      0.86      0.78        22\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.79      0.80      0.79        53\n",
      "weighted avg       0.81      0.79      0.79        53\n",
      "\n",
      "\n",
      "\n",
      "XGBClassifier CV roc_auc score: 0.9222902097902098\n",
      " --- XGBClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        33\n",
      "           1       0.63      0.85      0.72        20\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.76      0.77      0.75        53\n",
      "weighted avg       0.79      0.75      0.76        53\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "classifiers = [RandomForestClassifier(random_state= 1), GradientBoostingClassifier(random_state= 1), \n",
    "               SVC(random_state= 1), XGBClassifier(random_state = 1)]\n",
    "\n",
    "for pca_clf in classifiers: \n",
    "    pca_clf_scores = cross_val_score(pca_clf, X_pca_train, y_train, cv = 5, scoring = 'roc_auc')\n",
    "    print(f'{pca_clf.__class__.__name__} CV roc_auc score: {pca_clf_scores.mean()}')\n",
    "    \n",
    "    pca_clf.fit(X_pca_train, y_train)\n",
    "    pca_clf_pred = pca_clf.predict(X_pca_test)\n",
    "    print(f' --- {pca_clf.__class__.__name__} classification report ---')\n",
    "    print(classification_report(pca_clf_pred, y_test))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> UNSUCCESFULLL </h3>\n",
    "With the PCA approach, RF was barely able to beat the benchmark. Lets see how it performs without applying PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> WITHOUT PCA </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(sig)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, stratify= y, random_state= 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression CV roc_auc score: 0.8846666666666666\n",
      "--- LogisticRegression classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.81        31\n",
      "           1       0.70      0.86      0.78        22\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.79      0.80      0.79        53\n",
      "weighted avg       0.81      0.79      0.79        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state= 1)\n",
    "logreg_scores = cross_val_score(logreg, X_train, y_train, cv = 5, scoring= 'roc_auc')\n",
    "print(f'{logreg.__class__.__name__} CV roc_auc score: {cross_val_score(logreg, X_train, y_train, cv = 5).mean()}')\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "print(f'--- {logreg.__class__.__name__} classification report ---')\n",
    "print(classification_report(logreg_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier CV roc_auc score: 0.9598921911421912\n",
      " --- RandomForestClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85        28\n",
      "           1       0.81      0.88      0.85        25\n",
      "\n",
      "    accuracy                           0.85        53\n",
      "   macro avg       0.85      0.85      0.85        53\n",
      "weighted avg       0.85      0.85      0.85        53\n",
      "\n",
      "\n",
      "\n",
      "GradientBoostingClassifier CV roc_auc score: 0.9066142191142191\n",
      " --- GradientBoostingClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.84        29\n",
      "           1       0.78      0.88      0.82        24\n",
      "\n",
      "    accuracy                           0.83        53\n",
      "   macro avg       0.83      0.83      0.83        53\n",
      "weighted avg       0.84      0.83      0.83        53\n",
      "\n",
      "\n",
      "\n",
      "SVC CV roc_auc score: 0.9709401709401708\n",
      " --- SVC classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        33\n",
      "           1       0.63      0.85      0.72        20\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.76      0.77      0.75        53\n",
      "weighted avg       0.79      0.75      0.76        53\n",
      "\n",
      "\n",
      "\n",
      "XGBClassifier CV roc_auc score: 0.9529817404817404\n",
      " --- XGBClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87        29\n",
      "           1       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.87        53\n",
      "   macro avg       0.87      0.87      0.87        53\n",
      "weighted avg       0.87      0.87      0.87        53\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers: \n",
    "    clf_scores = cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'roc_auc')\n",
    "    print(f'{clf.__class__.__name__} CV roc_auc score: {clf_scores.mean()}')\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    print(f' --- {clf.__class__.__name__} classification report ---')\n",
    "    print(classification_report(clf_pred, y_test))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> SUCCESFULL </h3>\n",
    "All models managed to beat the baseline. This brings up the question, was it a poor PCA, or does the baseline work well with PCA? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</h3> HYPERPARAMETER TUNING RANDOM FOREST AND XGBCLASSIFIER </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF params: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 66}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from scipy.stats import randint, uniform \n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 3, random_state= 1)\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': randint(50, 150), \n",
    "    'max_depth': [3, 5, 7, None], \n",
    "    'min_samples_split': randint(2, 8), \n",
    "    'min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "rf = RandomForestClassifier(random_state= 1)\n",
    "rf_cv = RandomizedSearchCV(rf, param_distributions= rf_params, \n",
    "                           n_iter = 30, cv = cv, random_state= 1, n_jobs = -1)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "print('Best RF params:', rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB params: {'colsample_bytree': 0.6158734008262905, 'learning_rate': 0.09138763651723374, 'max_depth': 3, 'n_estimators': 137, 'reg_alpha': 0.15868120466108038, 'reg_lambda': 0.49430807720622444, 'subsample': 0.8318980876983187}\n"
     ]
    }
   ],
   "source": [
    "xgb_params  ={\n",
    "    'n_estimators': randint(50, 150), \n",
    "    'learning_rate': uniform(0.01, 0.1), \n",
    "    'max_depth': randint(2, 5), \n",
    "    'subsample': uniform (0.6, 0.4), \n",
    "    'colsample_bytree' : uniform(0.6, 0.4), \n",
    "    'reg_alpha': uniform(0, 0.5), \n",
    "    'reg_lambda': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state = 1)\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_distributions= xgb_params, \n",
    "                            n_iter = 30, cv = cv, random_state = 1, n_jobs = -1)\n",
    "\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "print('Best XGB params:', xgb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RandomForestClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87        27\n",
      "           1       0.85      0.88      0.87        26\n",
      "\n",
      "    accuracy                           0.87        53\n",
      "   macro avg       0.87      0.87      0.87        53\n",
      "weighted avg       0.87      0.87      0.87        53\n",
      "\n",
      "\n",
      "\n",
      "--- XGBClassifier classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87        27\n",
      "           1       0.85      0.88      0.87        26\n",
      "\n",
      "    accuracy                           0.87        53\n",
      "   macro avg       0.87      0.87      0.87        53\n",
      "weighted avg       0.87      0.87      0.87        53\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_clf = [rf_cv.best_estimator_, xgb_cv.best_estimator_]\n",
    "\n",
    "for clf in final_clf: \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    print(f'--- {clf.__class__.__name__} classification report ---')\n",
    "    print(classification_report(clf_pred, y_test))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both respectable scores. However, when I was playing around with this dataset, I found that a higher score could be obtained when not applying the Mann-Whitney test. This could hafe different reasons. Maybe the algorithms do better when they can decide on their own which classes are important. I will make a seperate file where I will test this too. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
